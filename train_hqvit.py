import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import pennylane as qml
from torchvision.models import vit_b_16, ViT_B_16_Weights
import medmnist
from medmnist import INFO
from tqdm import tqdm
from train_hqvit import UltimateHQViT
# ================= é…ç½®åŒºåŸŸ =================
BATCH_SIZE = 64          
LEARNING_RATE = 1e-4
EPOCHS = 5               
N_QUBITS = 4             
N_LAYERS = 2             
DATA_FLAG = 'pneumoniamnist' 

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”¥ è¿è¡Œè®¾å¤‡: {device} (Python 3.11)")

# ================= 1. æ•°æ®å‡†å¤‡ =================
def get_dataloaders():
    print(f"\n[1/4] æ­£åœ¨å‡†å¤‡ {DATA_FLAG} æ•°æ®é›†...")
    info = INFO[DATA_FLAG]
    DataClass = getattr(medmnist, info['python_class'])

    data_transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=3),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    train_dataset = DataClass(split='train', transform=data_transform, download=True)
    val_dataset = DataClass(split='val', transform=data_transform, download=True)

    print(f"âœ… æ•°æ®å°±ç»ª! è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(val_dataset)}")
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
    
    return train_loader, val_loader

# ================= 2. å®šä¹‰é‡å­å±‚ =================
# å¿…é¡»åœ¨ @qml.qnode ä¹‹å‰å®šä¹‰è®¾å¤‡
dev = qml.device("default.qubit", wires=N_QUBITS)

@qml.qnode(dev, interface="torch")
def quantum_circuit(inputs, weights):
    # A. ç¼–ç éƒ¨åˆ†
    qml.AngleEmbedding(inputs, wires=range(N_QUBITS))
    
    # B. å˜åˆ†éƒ¨åˆ† (Ring-VQC ç»“æ„)
    for i in range(N_LAYERS):
        for j in range(N_QUBITS):
            qml.RY(weights[i][j], wires=j)
        
        for j in range(N_QUBITS):
            qml.CNOT(wires=[j, (j + 1) % N_QUBITS])
            
    return [qml.expval(qml.PauliZ(wires=i)) for i in range(N_QUBITS)]

# ================= 3. å®šä¹‰æ··åˆæ¨¡å‹ (HQViT) =================
class HQViT(nn.Module):
    def __init__(self):
        super().__init__()
        print("[2/4] æ­£åœ¨åŠ è½½é¢„è®­ç»ƒ ViT æ¨¡å‹...")
        
        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)
        
        # å†»ç»“ ViT ä¸»ä½“å‚æ•°
        for param in self.vit.parameters():
            param.requires_grad = False
            
        # ä¿®æ”¹ Head è¾“å‡º N_QUBITS ä¸ªç‰¹å¾
        self.vit.heads.head = nn.Linear(768, N_QUBITS)
        
        # å®šä¹‰é‡å­å±‚
        weight_shapes = {"weights": (N_LAYERS, N_QUBITS)}
        self.quantum_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)
        
        # æœ€ç»ˆåˆ†ç±»å™¨
        self.classifier = nn.Linear(N_QUBITS, 2)
        
    def forward(self, x):
        x = self.vit(x)              
        x = torch.tanh(x) * 3.1415 
        x = self.quantum_layer(x)    
        x = self.classifier(x)       
        return x

# ================= 4. å®šä¹‰ Focal Loss =================
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.ce = nn.CrossEntropyLoss(reduction='none')

    def forward(self, inputs, targets):
        log_pt = -self.ce(inputs, targets)
        pt = torch.exp(log_pt)
        loss = self.alpha * (1 - pt) ** self.gamma * (-log_pt)
        return loss.mean()

# ================= 5. è®­ç»ƒä¸»å¾ªç¯ =================
def train():
    train_loader, val_loader = get_dataloaders()
    model = HQViT().to(device)
    
    # æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    criterion = FocalLoss()
    optimizer = optim.Adam(
        list(model.quantum_layer.parameters()) + 
        list(model.classifier.parameters()) + 
        list(model.vit.heads.head.parameters()),
        lr=LEARNING_RATE
    )
    
    print(f"\n[3/4] å¼€å§‹è®­ç»ƒ (å…± {EPOCHS} è½®)...")
    
    for epoch in range(EPOCHS):
        model.train()
        train_loss, correct, total = 0, 0, 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            labels = labels.squeeze().long()
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            pbar.set_postfix({'Loss': f"{loss.item():.4f}"})
        
        train_acc = 100 * correct / total
        
        # éªŒè¯è¿‡ç¨‹
        model.eval()
        val_correct, val_total = 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                labels = labels.squeeze().long()
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        val_acc = 100 * val_correct / val_total
        print(f"ğŸ Epoch {epoch+1} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%")

if __name__ == "__main__":
    train()
